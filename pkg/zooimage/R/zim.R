## Copyright (c) 2004-2012, Ph. Grosjean <phgrosjean@sciviews.org>
##
## This file is part of ZooImage
##
## ZooImage is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 2 of the License, or
## (at your option) any later version.
##
## ZooImage is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License
## along with ZooImage.  If not, see <http://www.gnu.org/licenses/>.

## Functions for manipulating .zim files (ZooImage Metadata/measurements)
## These.zim files contain metadata required to analyze plankton images
## and to record the way they were processed. Measurements on each identified
## object can also be appended in a table at the end of this file (in this case,
## the usual extension is '_dat1.zim' to indicate that data processed with
## ZooImage version 1 are present in the file).

#### OK ####
zimMake <- function (dir = ".", pattern = extensionPattern("tif"),
images = list.files(dir, pattern))
{
	## Check that there are images to process
	if (length(images) < 1)
		stop("no images to process!")

	## Name of images is something like SCS.xxxx-xx-xx.SS+Ann.tif
	## We make the same .zim file for all ...+Ann images, so, reduce the list
	zims <- sort(unique(sampleInfo(images, type = "fraction",
		ext = pattern)))
	zims <- file.path(dir, paste0(zims, ".zim"))
		
	## The process to run in batch
	makeZim <- function (zim) {
		if (!file.exists(zim)) {
			message("Processing .zim file ", basename(zim), "...")
			zimCreate(zim, template = getTemp(".template"), wait = TRUE)
			## Get this zim as new template
			assignTemp(".template", zim)
		} else message("Checking .zim file ", basename(zim), "...")
		## Verify that the .zim file is correct
		zimVerify(zim)
	}
	on.exit(rmTemp(".template"))
	batch(zims, makeZim)
}

#### OK ####
## Check if a file is a "(_dat1).zim" file (must start with "ZI1", "ZI2"
## or "ZI3" and have a '.zim' extension)
isZim <- function (zimfile)
{
	## Check if the file does not exist or is a directory
	if (!checkFileExists(zimfile, force.file = TRUE, extension = "zim"))
		return(FALSE)

	## Check the first line
	return(checkFirstLine(zimfile))
}

#### TODO: change all this! #### batcheable!
## Verify a "(_dat1).zim" file (all required fields + return the number of items
## in it). If it succeeds, return the number of measured items as numeric
## Otherwise, an error is generated by stop
zimVerify <- function (zimfile, is.dat1 = hasExtension(zimfile, "_dat1.zim"),
check.table = FALSE)
{
	## Required fields
	## Here are predefined required fields before measurements
	reqfields <- c("[Image]", "Author", "Hardware", "Software",
        "ImageType", "[Fraction]", "Code", "Min", "Max", "[Subsample]",
        "SubPart", "SubMethod", "CellPart", "Replicates", "VolIni",
        "VolPrec")

	## Then required fields when measurements are done
	reqfields2 <- c("[Process]")
	## Finally, required column headers
    reqcols <- c("!Item", "Label", "BX", "BY", "Width", "Height")

	## Determine if there are custom verification rules defined and if they
	## are active
    newRules <- getOption("ZI.zim")
    if (!is.null(newRules) && newRules$active == TRUE) {
        ## Do we delegate the whole process to a custom verification function?
		verifyAll <- newRules$verify.all
        if (!is.null(verifyAll) && inherits(verifyAll, "function"))
            return(verifyAll(zimfile = zimfile, is.dat1 = is.dat1,
				check.table = check.table))

		## Should we use additional verification code instead?
		verify <- newRules$verify
        reqfields <- c(reqfields, newRules$zim.required)
        reqfields2 <- c(reqfields2, newRules$dat1.zim.required)
        reqcols <- c(reqcols, newRules$dat1.data.required)
    } else verify <- NULL

	## Check that it is a zimfile
	if (!isZim(zimfile)) return(invisible(FALSE))

	## Run first the extra verification code
	if (!is.null(verify) && inherits(verify, "function")) {
		## We need to grab the error here and call stop from here to maintain
		## the old API and to allow the custom version of stop to be called
		## with the correct context of the zimVerify() function
		res <- try(verify(zimfile, is.dat1 = is.dat1,
            check.table = check.table), silent = TRUE)
		if (inherits(res, "try-error") || (is.character(res) && nchar(res))) {
			warning(res)
			return(invisible(FALSE))
		}
    }

	## Read the file...
	## Equal sign is used as comment char, in order to read only the field names
    Lines <- scan(zimfile, character(), sep = "\t", skip = 1, flush = TRUE,
		quiet = TRUE, blank.lines.skip = FALSE, comment.char = "=")

	if (!length(Lines)){
		warning(sprintf('File "%s" is empty', zimfile))
		return(invisible(FALSE))
	}

	## Trim leading and trailing white spaces
	Lines <- trimString(Lines)

	## Check that all required fields are present for a simple .zim file
    misfields <- reqfields[!(reqfields %in% Lines)]
    if (length(misfields) > 0) {
        warning(paste("Missing fields:", paste(misfields, collapse = ", ")))
		return(invisible(FALSE))
	}

	## Check if this is a _dat1.zim file with measurements
    if ("[Data]" %in% Lines) {
        ## Check for missing fields
		misfields2 <- reqfields2[!(reqfields2 %in% Lines)]
        if (length(misfields2) > 0) {
            warning(paste("Missing [Process] fields:", paste(misfields2,
				collapse = ", ")))
			return(invisible(FALSE))
		}

		## Check for required column headers
		posHeaders <- grep("^\\[Data\\]$", Lines)[1] + 1
		LineHeader <- scan(zimfile, character(), sep = "%", skip = posHeaders,
			nmax = 1, flush = TRUE, quiet = TRUE, comment.char = "=")
		Headers <- trimString(strsplit(LineHeader, "\t")[[1]])
		misHeaders <- reqcols[!(reqcols %in% Headers)]
		if (length(misHeaders) > 0) {
		    warning(paste("Missing columns in the table:", paste(misHeaders,
				collapse = ", ")))
			return(invisible(FALSE))
		}

		## Check that the table can be read
        if (check.table) {
			## Check the [Data] section
            posMes <- grep("^\\[Data\\]$", Lines)
            if (length(posMes) == 0) {
                warning("Trying to read the table of measurements but no [Data] section found!")
				return(invisible(FALSE))
            } else { # The [Data] section is found
				## we try to call read.table, catch the error, and throw it again
				## from here, because stop might have a different meaning
				## in the context of the zimVerify() function
				## allowing to use the zooImage calling handlers,
				## see errorHandling.R
				Mes <- try(read.table(zimfile, sep = "\t", header = TRUE,
					skip = posMes + 1), silent = TRUE)
				if (inherits(Mes, "try-error")) {
					warning(paste("Unable to read the table of measurements! : ",
						Mes))
					return(invisible(FALSE))
				} else { 	# Successful reading of the table of measurements
					return(nrow(Mes))	# Return the number of items measured
				}
            }
        } else {
			## Alternative method that does not read the table
			## We don't read the table, use a different method to get the number
			## of entries in it
			## Read the last entry in Lines and convert it to a numeric value:
			## should be the number of items measured
			nItems <- Lines[length(Lines)]
			if (sub("^[0-9]+$", "", nItems) != "") {
			    warning("Impossible to determine the number of items measured!")
				return(invisible(FALSE))
			}
			return(as.integer(nItems))
        }
    } else if (is.dat1) {
		warning("No measurements found in this file")
		return(invisible(FALSE))
	} else return(0)
}

## TODO: use batch() instead!
## Extract notes from .zip files and place them in .zim files
zimExtractAll <- function (zipdir = ".", zipfiles = zipList(zipdir),
path = NULL, replace = FALSE, check.unzip = TRUE, show.log = TRUE, bell = FALSE)
{
	## Make sure all zipfiles are in the same directory
	zipdirs <- dirname(zipfiles)
	if (length(unique(zipdirs)) > 1)
		stop("All zip files must be located in the same directory!")

	## Check that the dir exists!
	checkDirExists(zipdir)

	## Move to zipdir
    inidir <- getwd()
	setwd(zipdir)
	on.exit(setwd(inidir))
	zipdir <- getwd()   # That way, if we had ".", it is now expanded

	## Use only basenames for zip files
	zipfiles <- sort(basename(zipfiles))

	## Check that zipfiles exist
	if (!all(file.exists(zipfiles)))
		stop("One or several files not found!")

	## Look at the path where to place .zim files
	if (is.null(path)) {
		## The rule is the following one:
		## 1) if last subdir is "_raw", then place .zim file up one level
		## 2) else, place them in the same dir as the zip files
		path <- zipdir
		if (tolower(basename(path)) == "_raw") path <- dirname(path)
	} else {    # Look if this is a valid directory
		path <- path[1]
		checkDirExists(path)
	}

	## Compute the names of .zim files from the names of .zip files
	## Note: use only the fraction, that is, SCS.xxxx-xx-xx.SS+F from
	## SCS.xxxx-xx-xx.SS+Fnn)
	## If there are duplicates, only extract first one
	zimfiles <- sprintf( "%s.zim", sampleInfo(zipfiles, "fraction",
		ext = extensionPattern(".zip")))
	keep <- !duplicated(zimfiles)
	zimfiles <- zimfiles[keep]
	zipfiles <- zipfiles[keep]

	## Make full path for zimfiles
	zimfiles <- file.path(path, zimfiles)

	## If replace == FALSE, eliminate existing .zim files from the list
	if (!replace) {
		keep <- !file.exists(zimfiles)
		zimfiles <- zimfiles[keep]
		zipfiles <- zipfiles[keep]
	}

	## Are there files left
	if (length(zimfiles) == 0)
		stop("Done, no file to process!")

	## Extract .zim files, one at a time, and check them
	zmax <- length(zimfiles)

	ok <- sapply(1:zmax, function (i) {
		## Extract the .zim file from zip comment
		zipNoteGet(zipfiles[i], zimfiles[i])

		## Check that the .zim file is created
		if (zimVerify(zimfiles[i]) == 0) {
			warning("wrong zim file '", zimfiles[i], "'")
			return(FALSE)
		} else return(TRUE)
	})

	## Clean up
##	finishLoop(ok = all(as.logical(ok)), ok.console.msg = "",
##		nok.console.msg = "", bell = bell, show.log = show.log,
##		ok.log.msg = paste(zmax, ".zim files correctly extracted"),
##		nok.log.msg = paste(sum(!ok), "files not correctly extracted on", zmax))
}

## TODO: use batch() instead!
## Given a list of .zip files and a path where .zim files are located,
## the function updates comment fields of the .zip files with latest .zim content
zimRefreshAll <- function (zipdir = ".", zipfiles = zipList(zipdir),
zimdir = NULL, check.zip = TRUE, check.zim = TRUE, show.log = TRUE,
bell = FALSE)
{
    ## Make sure we have full path for zip files
	if (zipdir == ".") zipdir <- getwd()
	zipfiles <- file.path(zipdir, zipfiles)

    ## Check that zipfiles exist
	if (!all(file.exists(zipfiles)))
		stop("One or several .zip files not found!")

	## Look for the path where .zim files are located
	if (is.null(zimdir)) {
		## The rule is the following one:
		## 1) if last subdir of .zip files is "_raw", then .zim files
		##    should be up one level
		## 2) else, look at the same dir
		zimdir <- zipdir
		if (tolower(basename(zimdir)) == "_raw")
			zimdir <- dirname(zimdir)
	} else {    # Look if this is valid directory
		zimdir <- zimdir[1]
		checkDirExists(zimdir, message = "'%s' is not a valid directory!")
	}

	## Switch to that dir
	inidir <- getwd()
	setwd(zimdir)
	on.exit(setwd(inidir))

	## Compute the names of zim files from the names of zip files
	## Note: use only the fraction, that is, SCS.xxxx-xx-xx.SS+F from
	## SCS.xxxx-xx-xx.SS+Fnn)
	## If there are duplicates, only extract first one
	zimfiles <- sprintf( "%s.zim",
		sampleInfo(zipfiles, "fraction", ext = extensionPattern("zip")))

	## Eliminate path for zimfiles
	zimfiles <- basename(zimfiles)

	## Keep only existing .zim files
	keep <- file.exists(zimfiles)
	zimfiles <- zimfiles[keep]
	zipfiles <- zipfiles[keep]

	## Are there files left?
	if (length(zimfiles) == 0)
		stop("Done, no file to update!")

	## Check the zim files using zimVerify() if necessary
##	logClear()
	ok <- TRUE
	if (check.zim) {
		message("Verification of .zim files...")
		zfiles <- unique(zimfiles)
		zmax <- length(zfiles)

		oks <- sapply(1:zmax, function (z) {
			progress(z, zmax)
			return(zimVerify(zfiles[z]))
		})
		ok <- all(oks)
		progress(101) # Clear progression indicator
	}

	if (ok) {
		message("-- Done! --")
	} else {
		warning(zimdir,
			" contains corrupted .zim files, compression not started!")
		return(invisible(FALSE))
	}

	## If everything is OK, update comments in the zip files with the content
	## of the .zim files
	imax <- length(zipfiles)
	message("Update of .zip comments...")
	for (i in 1:imax) {
		progress(i, imax)

		## Replace the zip comment with content of the corresponding .zim file
		zipNoteAdd(zipfiles[i] , zimfiles[i])
	}
	progress(101) # Clear progression indicator

	## Clean up
##	finishLoop(ok, bell = bell, show.log = show.log)
}

## Create a .zim file
zimCreate <- function (zimfile, template = NULL,
edit = TRUE, editor = getOption("fileEditor"), wait = FALSE)
{
	## Create a .zim file from a template and edit it
	if (missing(zimfile) || is.null(zimfile) || zimfile == "") {
		zimfile <- dlgInput("Give a name for the new .zim file:",
			title = "ZIM file creation", default = "myfile.zim")$res
		if (!length(zimfile)) return(invisible(FALSE))
		if (!hasExtension(zimfile, "zim"))
			zimfile <- paste(zimfile, ".zis", sep = "")
	}

	## If the file exists, edit existing version instead
    if (file.exists(zimfile))
		if (isTRUE(edit)) {
			return(zimEdit(zimfile, editor = editor, wait = wait))
		} else return(invisible(TRUE))

	## Look for the template
	if (is.null(template))
		template <- file.path(getOption("ZITemplates"), "default.zim")
	if (!isZim(template)) return(invisible(FALSE))
	## Copy the template into the new file
	file.copy(template, zimfile)
	
	## Possibly edit this new file
	if (isTRUE(edit)) {
		return(zimEdit(zimfile, editor = editor, wait = wait))
	} else return(invisible(TRUE))
}

## Edit a .zim file
zimEdit <- function (zimfile, editor = getOption("fileEditor"), wait = FALSE, ...)
{
	if (missing(zimfile) || !length(zimfile) || zimfile == "") {
		zimfile <- selectFile("Zim")
		if (zimfile == "") return(invisible(FALSE))
	} else if (!isZim(zimfile)) return(invisible(FALSE))
	fileEdit(zimfile, editor = editor, wait = wait, ...)
}

## FlowCAM special treatment because the plugin doesn't export dat1.zim!
## read list file
lstRead <- function (lstfile, skip = 2)
{
	## Determine the version of the FlowCAM
	ncol <- length(read.table(lstfile, header = FALSE, sep = ":", dec = ".", skip = 2,
		nrows = 1))
	if (ncol <= 44) {
		## FlowCAM II with 44 columns
		## read the table
		tab <- read.table(lstfile, header = FALSE, sep = ":", dec = '.',
			col.names = c("Id", "FIT_Cal_Const", "FIT_Raw_Area",
				"FIT_Raw_Feret_Max", "FIT_Raw_Feret_Min", "FIT_Raw_Feret_Mean",
				"FIT_Raw_Perim", "FIT_Raw_Convex_Perim", "FIT_Area_ABD",
				"FIT_Diameter_ABD", "FIT_Length", "FIT_Width",
				"FIT_Diameter_ESD", "FIT_Perimeter", "FIT_Convex_Perimeter",
				"FIT_Intensity", "FIT_Sigma_Intensity", "FIT_Compactness",
				"FIT_Elongation", "FIT_Sum_Intensity", "FIT_Roughness",
				"FIT_Feret_Max_Angle", "FIT_Avg_Red", "FIT_Avg_Green",
				"FIT_Avg_Blue", "FIT_PPC", "FIT_Ch1_Peak", "FIT_Ch1_TOF",
				"FIT_Ch2_Peak", "FIT_Ch2_TOF", "FIT_Ch3_Peak", "FIT_Ch3_TOF",
				"FIT_Ch4_Peak", "FIT_Ch4_TOF", "FIT_Filename", "FIT_SaveX",
				"FIT_SaveY", "FIT_PixelW", "FIT_PixelH", "FIT_CaptureX",
				"FIT_CaptureY", "FIT_High_U32", "FIT_Low_U32", "FIT_Total"),
			skip = skip)
		## Add columns present in list files from FlowCAM III
		tab$FIT_Feret_Min_Angle <- NA
		tab$FIT_Edge_Gradient <- NA
		tab$FIT_Timestamp1 <- NA
		tab$FIT_Timestamp2 <- NA
		tab$FIT_Source_Image <- NA
		tab$FIT_Calibration_Image <- NA
		tab$FIT_Ch2_Ch1_Ratio <- tab$FIT_Ch2_Peak / tab$FIT_Ch1_Peak
		## New variables calculation (present in dataexport.csv from the FlowCAM)
		tab$FIT_Volume_ABD <- (4/3) * pi * (tab$FIT_Diameter_ABD/2)^3
		tab$FIT_Volume_ESD <- (4/3) * pi * (tab$FIT_Diameter_ESD/2)^3
		tab$FIT_Aspect_Ratio <- tab$FIT_Width / tab$FIT_Length
		tab$FIT_Transparency <- 1 - (tab$FIT_Diameter_ABD/tab$FIT_Diameter_ESD)
		tab$FIT_Red_Green_Ratio <- tab$FIT_Avg_Red / tab$FIT_Avg_Green
		tab$FIT_Blue_Green_Ratio <- tab$FIT_Avg_Blue / tab$FIT_Avg_Green
		tab$FIT_Red_Blue_Ratio <- tab$FIT_Avg_Red / tab$FIT_Avg_Blue
	} else { # FlowCAM III with 47 columns
		## Read the table
		tab <- read.table(lstfile, header = FALSE, sep = ":", dec = '.',
			col.names = c("Id", "FIT_Cal_Const", "FIT_Raw_Area",
				"FIT_Raw_Feret_Max", "FIT_Raw_Feret_Min", "FIT_Raw_Feret_Mean",
				"FIT_Raw_Perim", "FIT_Raw_Convex_Perim", "FIT_Area_ABD",
				"FIT_Diameter_ABD", "FIT_Length", "FIT_Width",
				"FIT_Diameter_ESD", "FIT_Perimeter", "FIT_Convex_Perimeter",
				"FIT_Intensity", "FIT_Sigma_Intensity", "FIT_Compactness",
				"FIT_Elongation", "FIT_Sum_Intensity", "FIT_Roughness",
				"FIT_Feret_Max_Angle", "FIT_Feret_Min_Angle", "FIT_Avg_Red",
				"FIT_Avg_Green", "FIT_Avg_Blue", "FIT_PPC", "FIT_Ch1_Peak",
				"FIT_Ch1_TOF", "FIT_Ch2_Peak", "FIT_Ch2_TOF", "FIT_Ch3_Peak",
				"FIT_Ch3_TOF", "FIT_Ch4_Peak", "FIT_Ch4_TOF", "FIT_Filename",
				"FIT_SaveX", "FIT_SaveY", "FIT_PixelW", "FIT_PixelH",
				"FIT_CaptureX", "FIT_CaptureY", "FIT_Edge_Gradient",
				"FIT_Timestamp1", "FIT_Timestamp2", "FIT_Source_Image",
				"FIT_Calibration_Image"),
			skip = skip)
		## Add columns present in list files from FlowCAM II
		tab$FIT_High_U32 <- NA
		tab$FIT_Low_U32 <- NA
		tab$FIT_Total <- NA
		## New variables calculation (present in dataexport.csv from the FlowCAM)
		tab$FIT_Volume_ABD <- (4/3) * pi * (tab$FIT_Diameter_ABD/2)^3
		tab$FIT_Volume_ESD <- (4/3) * pi * (tab$FIT_Diameter_ESD/2)^3
		tab$FIT_Aspect_Ratio <- tab$FIT_Width / tab$FIT_Length
		tab$FIT_Transparency <- 1 - (tab$FIT_Diameter_ABD/tab$FIT_Diameter_ESD)
		tab$FIT_Red_Green_Ratio <- tab$FIT_Avg_Red / tab$FIT_Avg_Green
		tab$FIT_Blue_Green_Ratio <- tab$FIT_Avg_Blue / tab$FIT_Avg_Green
		tab$FIT_Red_Blue_Ratio <- tab$FIT_Avg_Red / tab$FIT_Avg_Blue
		tab$FIT_Ch2_Ch1_Ratio <- tab$FIT_Ch2_Peak / tab$FIT_Ch1_Peak
	}
	return(tab)
}

## Read context file
## TODO: avoid duplicated code between versions
ctxRead <- function(ctxfile, fil = FALSE, largest = FALSE, vignettes = TRUE,
scalebar = TRUE, enhance = FALSE, outline = FALSE, masks = FALSE,
verbose = TRUE)
{
	## Check arguments
	if (!is.character(ctxfile)) stop("You must select one context file")
	## Extract information from context file
	## Scan the ctx file
	ctxdata <- scan(ctxfile, character(), sep = "\t", skip = 0,
		blank.lines.skip = FALSE, flush = TRUE, quiet = TRUE, comment.char = "")
	## Read version of Visual SpreadSheet
	ImageLine <- grep("^SoftwareVersion", ctxdata)
	SoftwareVersion <- as.character(sub("[ ]*$", "",
		sub("^SoftwareVersion[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
	Version <- sub("...$", "", SoftwareVersion)
	## Read right parameters
	if (Version == "1.5") {
		## Read recalibration duration
		ImageLine <- grep("^SaveIntervalMinutes", ctxdata)
		interval <- as.numeric(sub("[ ]*$", "",
			sub("^SaveIntervalMinutes[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read pixel size
		ImageLine <- grep("^CalibrationConstant", ctxdata)
		pixelsize <- as.numeric(sub("[ ]*$", "",
			sub("^CalibrationConstant[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read minimal size
		ImageLine <- grep("^MinESD", ctxdata)
		minsize <- as.numeric(sub("[ ]*$", "",
			sub("^MinESD[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read maximal size
		ImageLine <- grep("^MaxESD", ctxdata)
		maxsize <- as.numeric(sub("[ ]*$", "",
			sub("^MaxESD[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read the kind of segmentation used
		ImageLine <- grep("^CaptureDarkOrLightPixels", ctxdata)
		DarkOrLight <- as.numeric(sub("[ ]*$", "",
			sub("^CaptureDarkOrLightPixels[ ]*[=][ ]*", "",
				ctxdata[ImageLine[1]])))
		if (DarkOrLight == 0) {
			use <- "dark"
		} else if (DarkOrLight == 1) {
			use <- "light"	
		} else use <- "both"
		## Read segmentation threshold
		ImageLine <- grep("^Threshold", ctxdata)
		thresholddark <- as.numeric(sub("[ ]*$", "",
			sub("^Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		thresholdlight <- as.numeric(sub("[ ]*$", "",
			sub("^Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
    
		## Path of the export of data
		select <- file.path(basename(dirname(ctxfile)), "data_export.csv")
		## Sample name
		Sample_Name <- basename(dirname(ctxfile))
		## Read Fluo information
		ImageLine <- grep("^Ch1Gain", ctxdata)
		Gain_Fluo_Ch1 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch1Gain[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^Ch1Threshold", ctxdata)
		Threshold_Fluo_Ch1 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch1Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^Ch2Gain", ctxdata)
		Gain_Fluo_Ch2 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch2Gain[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^Ch2Threshold", ctxdata)
		Threshold_Fluo_Ch2 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch2Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read information about FlowCell
		ImageLine <- grep("^FlowCellDepth", ctxdata)
		FlowCell <- as.numeric(sub("[ ]*$", "",
			sub("^FlowCellDepth[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Distance to nearest
		ImageLine <- grep("^DistanceToNeighbor", ctxdata)
		Dist_To_Nearest <- as.numeric(sub("[ ]*$", "",
			sub("^DistanceToNeighbor[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Calculation of volume analyzed
		## Number of raw images analyzed
		ImageLine <- grep("^RawImageTotal", ctxdata)
		Raw <- as.numeric(sub("[ ]*$", "",
			sub("^RawImageTotal[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Area analysed (Length * Width) in pixels
		ImageLine <- grep("^AcceptableLeft", ctxdata)
		Left <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableLeft[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableRight", ctxdata)
		Right <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableRight[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableTop", ctxdata)
		Top <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableTop[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableBottom", ctxdata)
		Bottom <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableBottom[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Calculation of area of one image in
		## µm <= (R-L * PixelSize) * (B-T * PixelSize)
		Area <- ((Right - Left) * pixelsize) * ((Bottom - Top) * pixelsize)
		## Total volume analysed (cm³ = ml)
		VolumeDigitized <- (Area/(10^8)) * (FlowCell/10000) * Raw
		## New fields in the ctx FlowCAM III
		Threshold_Scatter <- NA
		VolumeDigitized_VIS <- NA
		Dilution_VIS <- NA
		AutoImageRate <- NA
		FlashDuration <- NA
	} else if (Version == "2.1" || Version == "2.2") {
		## Fields not present in new version
		Gain_Fluo_Ch1 <- NA
		Gain_Fluo_Ch2 <- NA
		## Read recalibration duration
		ImageLine <- grep("^RecalibrationIntervalMinutes", ctxdata)
		interval <- as.numeric(sub("[ ]*$", "",
			sub("^RecalibrationIntervalMinutes[ ]*[=][ ]*", "",
			ctxdata[ImageLine[1]])))
		## Read pixel size
		ImageLine <- grep("^CalibrationConstant", ctxdata)
		pixelsize <- as.numeric(sub("[ ]*$", "",
			sub("^CalibrationConstant[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read minimal size
		ImageLine <- grep("^MinESD", ctxdata)
		minsize <- as.numeric(sub("[ ]*$", "",
			sub("^MinESD[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read maximal size
		ImageLine <- grep("^MaxESD", ctxdata)
		maxsize <- as.numeric(sub("[ ]*$", "",
			sub("^MaxESD[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read the kind of segmentation used
		ImageLine <- grep("^CaptureDarkOrLightPixels", ctxdata)
		CaptureDarkOrLightPixels <- as.numeric(sub("[ ]*$", "",
			sub("^CaptureDarkOrLightPixels[ ]*[=][ ]*", "",
			ctxdata[ImageLine[1]])))
		if (CaptureDarkOrLightPixels == 0) {
			use <- "dark"
		} else if (CaptureDarkOrLightPixels == 1) {
			use <- "light"
		} else use <- "both"
		## Read segmentation threshold
		ImageLine <- grep("^ThresholdDark", ctxdata)
		thresholddark <- as.numeric(sub("[ ]*$", "",
			sub("^ThresholdDark[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^ThresholdLight", ctxdata)
		thresholdlight <- as.numeric(sub("[ ]*$", "",
			sub("^ThresholdLight[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))

		## Path of the export of data
		ImageLine <- grep("^AutoExportList", ctxdata)
		AutoExportList <- as.numeric(sub("[ ]*$", "",
			sub("^AutoExportList[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		if (AutoExportList == 1) {
			select <- file.path(basename(dirname(ctxfile)),
				paste(basename(dirname(ctxfile)),"csv", sep = "."))
		} else {
			select <- file.path(basename(dirname(ctxfile)), "data_export.csv")
		}
		## Sample name
		Sample_Name <- basename(dirname(ctxfile))
		## Read Fluo information
		ImageLine <- grep("^Ch1Threshold", ctxdata)
		Threshold_Fluo_Ch1 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch1Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^Ch2Threshold", ctxdata)
		Threshold_Fluo_Ch2 <- as.numeric(sub("[ ]*$", "",
			sub("^Ch2Threshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read Scatter information
		ImageLine <- grep("^ScatterThreshold", ctxdata)
		Threshold_Scatter <- as.numeric(sub("[ ]*$", "",
			sub("^ScatterThreshold[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Read information about FlowCell
		ImageLine <- grep("^FlowCellDepth", ctxdata)
		FlowCell <- as.numeric(sub("[ ]*$", "",
			sub("^FlowCellDepth[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Distance to nearest
		ImageLine <- grep("^DistanceToNeighbor", ctxdata)
		Dist_To_Nearest <- as.numeric(sub("[ ]*$", "",
			sub("^DistanceToNeighbor[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Calculation of volume analyzed
		## Number of raw images analyzed
		ImageLine <- grep("^RawImageTotal", ctxdata)
		Raw <- as.numeric(sub("[ ]*$", "",
			sub("^RawImageTotal[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Area analysed (Length * Width) in pixels
		ImageLine <- grep("^AcceptableLeft", ctxdata)
		Left <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableLeft[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableRight", ctxdata)
		Right <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableRight[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableTop", ctxdata)
		Top <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableTop[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		ImageLine <- grep("^AcceptableBottom", ctxdata)
		Bottom <- as.numeric(sub("[ ]*$", "",
			sub("^AcceptableBottom[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Calculation of area of one image in µm
		## <= (R-L * PixelSize) * (B-T * PixelSize)
		Area <- ((Right - Left) * pixelsize) * ((Bottom - Top) * pixelsize)
		## Total volume analysed (cm³ = ml)
		VolumeDigitized <- (Area/(10^8)) * (FlowCell/10000) * Raw
		## Total volume analyzed calculated by Visual Spreadsheet
		ImageLine <- grep("^TotalVolumeML", ctxdata)
		VolumeDigitized_VIS <- as.numeric(sub("[ ]*$", "",
			sub("^TotalVolumeML[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Dilution
		ImageLine <- grep("^VolumeCalibrationFactor", ctxdata)
		Dilution_VIS <- as.numeric(sub("[ ]*$", "",
			sub("^VolumeCalibrationFactor[ ]*[=][ ]*", "",
			ctxdata[ImageLine[1]])))
		## AutoImage
		ImageLine <- grep("^AutoImageRate", ctxdata)
		AutoImageRate <- as.numeric(sub("[ ]*$", "",
		sub("^AutoImageRate[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
		## Flash Duration
		ImageLine <- grep("^FlashDuration", ctxdata)
		FlashDuration <- as.numeric(sub("[ ]*$", "",
		sub("^FlashDuration[ ]*[=][ ]*", "", ctxdata[ImageLine[1]])))
	}
	## Create a table
	res <- data.frame(select, interval, pixelsize, minsize, maxsize, use,
		thresholddark, thresholdlight, fil = fil, largest = largest,
		vignettes = vignettes, scalebar = scalebar, enhance = enhance,
		outline = outline, masks = masks, verbose = verbose, Sample_Name,
		FlowCell, Gain_Fluo_Ch1, Threshold_Fluo_Ch1, Gain_Fluo_Ch2,
		Threshold_Fluo_Ch2, Threshold_Scatter, Dist_To_Nearest, VolumeDigitized,
		VolumeDigitized_VIS, SoftwareVersion, Dilution_VIS, AutoImageRate,
		FlashDuration)
	## Print results
	return(res)
}

## Read several ctx files
ctxReadAll <- function (ctxfile, fil = FALSE, largest = FALSE, vignettes = TRUE,
scalebar = TRUE, enhance = FALSE, outline = FALSE, masks = FALSE,
verbose = TRUE)
{
	## Check arguments
	if (!is.character(ctxfile)) stop("You must select one context file")
	## List all ctx files to read
	ListCtx <- list.files(path = dirname(dirname(ctxfile)), pattern = "\\.ctx$",
		all.files = FALSE, full.names = TRUE, recursive = TRUE)
	## Make a loop to read each one
	lListCtx <- length(ListCtx)
	if (lListCtx > 1) {
		## More than one ctx file to read
		AllCtx <- ctxRead(ListCtx[i], fil = fil, largest = largest,
			vignettes = vignettes, scalebar = scalebar, enhance = enhance,
			outline = outline, masks = masks, verbose = verbose)
		for (i in 2:lListCtx)
			AllCtx <- rbind(AllCtx, ctxRead(ListCtx[i], fil = fil,
				largest = largest, vignettes = vignettes, scalebar = scalebar,
				enhance = enhance, outline = outline, masks = masks,
				verbose = verbose))
	} else {
		## Only one ctx file to read
		AllCtx <- ctxRead(ListCtx, fil = FALSE, largest = FALSE,
			vignettes = TRUE, scalebar = TRUE, enhance = FALSE, outline = FALSE,
			masks = FALSE, verbose = TRUE)
	}
	return(AllCtx)
}

## Create a zim file for FlowCAM images
zimMakeFlowCAM <- function (import = ".", check.names = TRUE)
{
	## Importation methods for FlowCAM data
	if (!is.character(import))
		stop("You must select a import text file for FlowCAM images")
	## Read this file
	ImportFile <- read.table(import, header = TRUE, sep = "\t", dec = ".")

	## Check colnames
	if (isTRUE(check.names)) {
		ColNames <- c("Station", "Date", "FlowCell", "Mode", "Magnification",
			"Exp_Name", "Sample", "Dilution", "Sieve", "Volume", "Pump_Speed",
			"Duration", "Temperature", "Salinity", "Gain_Fluo_Ch1",
			"Threshold_Fluo_Ch1", "Gain_Fluo_Ch2", "Threshold_Fluo_Ch2",
			"Threshold_Scatter", "Min", "Max", "Size")
		if (!all(ColNames %in% colnames(ImportFile)))
			stop("Your import file contains missing columns among Station,",
				" Date, FlowCell, Mode, Magnification, Exp_Name, Sample,",
				" Dilution, Sieve, Volume, Pump_Speed, Duration, Temperature,",
				" Salinity, Gain_Fluo_Ch1, Threshold_Fluo_Ch1, Gain_Fluo_Ch2,",
				" Threshold_Fluo_Ch2, Threshold_Scatter, Min, Max, or Size")
	}
  
	## Check if the ImportTemplate.zie is present in the directory
	if (!file.exists(file.path(dirname(import), "ImportTemplate.zie")))
		stop("Your directory must contain an 'ImportTemplate.zie' file")
  
	## Check if all samples are in the directory and export missing files
	notThere <- character(0)
	for (i in 1:length(ImportFile$Exp_Name)) {
		if (!file.exists(file.path(dirname(import), ImportFile$Exp_Name[i]))) {
			notThere <- c(notThere, as.character(ImportFile$Exp_Name[i]))
			cat(ImportFile$Exp_Name[i], "is not in the process directory\n")
		}
	}
  
	## Select only samples present in the process directory
	if (length(notThere)) {
		ImportFile <- ImportFile[!ImportFile$Exp_Name %in% notThere, ]
		cat("Only import samples in the process dir or the import text file\n")
	}

	## Read ctx files of the samples from
	Ctx <- file.path(dirname(import), ImportFile$Exp_Name,
		paste(ImportFile$Exp_Name, "ctx", sep = "."))
	lCtx <- length(Ctx)
	if (!lCtx) {
		CtxFile <- NULL
	} else {
		CtxFile <- ctxRead(Ctx[1])
		if (lCtx > 1) for (i in 2:lCtx) CtxFile <- rbind(CtxFile, ctxRead(Ctx[i]))
	}
	## Create fields to generate a table as txt format for the importation
	Experiment <- ImportFile$Exp_Name
	Sample <- ImportFile$Sample
	Image <- CtxFile$Sample_Name
	PixelSize <- CtxFile$pixelsize
	minsize <- CtxFile$minsize
	maxsize <- CtxFile$maxsize
	VolumeDigitized <- CtxFile$VolumeDigitized
	Dilution_VIS <- CtxFile$Dilution_VIS
	SubPart <- ImportFile$Dilution / 100
	VolIni <- ImportFile$Volume
	CellPart <- VolumeDigitized / VolIni
	## Table with value to change
	ImportTxt <- data.frame(Experiment, Sample, Image, PixelSize, SubPart,
		minsize, maxsize, VolumeDigitized, Dilution_VIS, VolIni, CellPart)
	## Check if "ImportTemplate.zie" file exists
	Zie <- file.path(dirname(import), "ImportTemplate.zie")
	if (!file.exists(Zie))
		stop("There is no 'ImportTemplate.zie' file in the process directory")
	## Read the "ImportTemplate.zie" file
	ZieFileOrig <- scan(Zie, character(), sep = "\t", skip = 0,
		blank.lines.skip = FALSE, flush = TRUE, quiet = TRUE, comment.char = "")
	## Loop to create a file _dat1.zim
	for (i in 1:nrow(CtxFile)) {
		ZieFile <- ZieFileOrig
		## Complete fields using ImportTxt
		ImageLine <- grep("^Sample", ZieFile)
		Sample <- as.numeric(sub("[ ]*$", "", sub("^Sample[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(Sample)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$Sample[i], sep = "")
		ImageLine <- grep("^Experiment", ZieFile)
		Experiment <- as.numeric(sub("[ ]*$", "",
			sub("^Experiment[ ]*[=][ ]*", "", ZieFile[ImageLine[1]])))
		if (is.na(Experiment)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$Experiment[i], sep = "")
		ImageLine <- grep("^SubPart", ZieFile)
		SubPart <- as.numeric(sub("[ ]*$", "", sub("^SubPart[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(SubPart)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$SubPart[i], sep = "")
		ImageLine <- grep("^CellPart", ZieFile)
		CellPart <- as.numeric(sub("[ ]*$", "", sub("^CellPart[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(CellPart)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$CellPart[i], sep = "")
		ImageLine <- grep("^Dilution_VIS", ZieFile)
		Dilution_VIS <- as.numeric(sub("[ ]*$", "",
			sub("^Dilution_VIS[ ]*[=][ ]*", "", ZieFile[ImageLine[1]])))
		if (is.na(Dilution_VIS)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$Dilution_VIS[i], sep = "")
		ImageLine <- grep("^VolIni", ZieFile)
		VolIni <- as.numeric(sub("[ ]*$", "", sub("^VolIni[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(VolIni)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$VolIni[i], sep = "")
		ImageLine <- grep("^VolumeDigitized", ZieFile)
		VolumeDigitized <- as.numeric(sub("[ ]*$", "",
			sub("^VolumeDigitized[ ]*[=][ ]*", "", ZieFile[ImageLine[1]])))
		if (is.na(VolumeDigitized)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$VolumeDigitized[i], sep = "")
		ImageLine <- grep("^minsize", ZieFile)
		minsize <- as.numeric(sub("[ ]*$", "", sub("^minsize[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(minsize)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$minsize[i], sep = "")
		ImageLine <- grep("^maxsize", ZieFile)
		maxsize <- as.numeric(sub("[ ]*$", "", sub("^maxsize[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(maxsize)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$maxsize[i], sep = "")
		ImageLine <- grep("^PixSize", ZieFile)
		PixSize <- as.numeric(sub("[ ]*$", "", sub("^PixSize[ ]*[=][ ]*", "",
			ZieFile[ImageLine[1]])))
		if (is.na(PixSize)) ZieFile[ImageLine[1]] <-
			paste(ZieFile[ImageLine[1]], ImportTxt$PixelSize[i], sep = "")
		## Read all context file
		ContextFile <- scan(Ctx[i], character(), sep = "\t", skip = 0,
			blank.lines.skip = FALSE, flush = TRUE, quiet = TRUE, comment.char = "")

		## Read note
		Note <- file.path(dirname(import), ImportFile$Exp_Name[i],
			paste(ImportFile$Exp_Name[i], "_notes.txt", sep = ""))
		NoteFile <- scan(Note, character(), sep = "\t", skip = 0,
			blank.lines.skip = FALSE, flush = TRUE, quiet = TRUE, comment.char = "")
		## Write table in the sample directory
		Tab <- c(ZieFile, "", ContextFile, "", "[Notes]", NoteFile)
		Export <- file.path(dirname(import), CtxFile$Sample_Name[i],
			paste(CtxFile$Sample_Name[i], "zim", sep = "."))
		write(Tab, file = Export)
	}
}

## Create a dat1.zim file by pooling lst and results.csv tables
zimDatMake <- function (zimfile)
{
	## Check if the zim file exists
	if (!file.exists(zimfile))
		stop(basename(zimfile), " is not found")
	## Dir containing the .zim file
	zidir <- dirname(zimfile)
	## Read list file
	lstfile <- file.path(zidir, paste(basename(zidir), "lst", sep = "."))
	## Read visual spreadsheet data (from the FlowCAM)
	visdata <- lstRead(lstfile, skip = 2)
	## Read ImageJ results (from FITVis)
	ijdata <- read.table(file.path(zidir, "results.csv"),
		sep = ",", header = TRUE, dec = ".")
	## Create a General table of mesurements
	alldata <- cbind(visdata, ijdata)
	## Add Label columns
	alldata$Label <- rep(basename(zidir), nrow(alldata))
	## Transform Id column in !Item column
	names(alldata)[grep("Id", names(alldata))] <- "!Item"
	## Select only useful columns
	alldata$FIT_Filename <- NULL
	## Create _dat1.zim file
	zidatfile <- file.path(zidir, basename(zidir), basename(zimfile))
	if (!file.exists(dirname(zidatfile)))
		stop("Directory ", dirname(zidatfile), " does not exist")
	file.copy(from = zimfile, to = zidatfile, overwrite = FALSE)
	## Add table of measurements at the end
	cat("\n[Data]\n", file = zidatfile, append = TRUE)
	write.table(alldata, file = zidatfile, append = TRUE, quote = FALSE,
		sep = "\t", col.names = TRUE, row.names = FALSE, dec = ".")
	## Rename the _dat1.zim file
	zidat1file <- file.path(dirname(zidatfile),
		sub("\\.zim$", "_dat1.zim", basename(zimfile)))
	file.rename(from = zidatfile, to = zidat1file)
}

## Create several dat1.zim files
## TODO: rework this and use log file!
zimDatMakeAll <- function (zimfile)
{
	## Search all zim files in process directory
	procdir <- dirname(dirname(zimfile))
	allzim <- list.files(path = procdir, pattern = "\\.zim$", all.files = FALSE,
		full.names = TRUE, recursive = TRUE)
	if (!length(allzim)) return()
	## Loop to automatically create dat1.zim files
	for (i in 1:length(allzim)) zimDatMake(allzim[i])
}
